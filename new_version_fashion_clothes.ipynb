{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da81672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 12:38:11.302352: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07956eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-15 12:38:18--  https://github.com/alexeygrigorev/mlbookcamp-code/releases/download/chapter7-model/xception_v4_large_08_0.894.h5\n",
      "Resolving github.com (github.com)... 140.82.113.4\n",
      "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/256401220/0156a400-0049-11eb-8490-c0d01b48ea8c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230315%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230315T123818Z&X-Amz-Expires=300&X-Amz-Signature=fbe2deac8bd5cc3a60fc8734bbf9aec4b069092e425f7f1798415bf6b82551d1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=256401220&response-content-disposition=attachment%3B%20filename%3Dxception_v4_large_08_0.894.h5&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-03-15 12:38:18--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/256401220/0156a400-0049-11eb-8490-c0d01b48ea8c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230315%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230315T123818Z&X-Amz-Expires=300&X-Amz-Signature=fbe2deac8bd5cc3a60fc8734bbf9aec4b069092e425f7f1798415bf6b82551d1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=256401220&response-content-disposition=attachment%3B%20filename%3Dxception_v4_large_08_0.894.h5&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 86185888 (82M) [application/octet-stream]\n",
      "Saving to: ‘clothing-model.h5’\n",
      "\n",
      "clothing-model.h5   100%[===================>]  82.19M   154MB/s    in 0.5s    \n",
      "\n",
      "2023-03-15 12:38:19 (154 MB/s) - ‘clothing-model.h5’ saved [86185888/86185888]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/alexeygrigorev/mlbookcamp-code/releases/download/chapter7-model/xception_v4_large_08_0.894.h5 -O clothing-model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5176e864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a58f40a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8f1d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('clothing-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43335d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e70943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('./clothing-dataset-small/test/longsleeve/0f4d9494-612a-48f8-be05-e47f4fc54d54.jpg' , target_size=(299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f258736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "clothing_list = ['dress', 'hat', 'longsleeve', 'outwear', 'pants', 'shirt', 'shoes', 'shorts', 'skirt', 't-shirt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98dfce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    " def prediction(image):  \n",
    "    path = f'clothing-dataset-small/test/pants/{image}'\n",
    "    img = load_img(path, target_size=(299, 299))\n",
    "    x = np.array(img)\n",
    "    X = np.array([x])\n",
    "    X = preprocess_input(X)\n",
    "    pred = model.predict(X)\n",
    "    max_index = pred[0].argmax()\n",
    "    best = clothing_list[max_index]\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "190c4a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 12:38:42.693808: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-03-15 12:38:43.339427: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-15 12:38:43.340271: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-15 12:38:43.340313: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-03-15 12:38:43.341401: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-15 12:38:43.341500: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "pred = prediction(image ='046d0a65-f5a6-47f6-afaf-e692bfcfcb00.jpg' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "832a2906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pants'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff347b1",
   "metadata": {},
   "source": [
    "**Converter Keras to TF-Lite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e37d952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvr47juxp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpvr47juxp/assets\n",
      "2023-03-15 12:39:13.802496: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-03-15 12:39:13.802546: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-03-15 12:39:13.803395: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpvr47juxp\n",
      "2023-03-15 12:39:13.831300: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2023-03-15 12:39:13.831335: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: /tmp/tmpvr47juxp\n",
      "2023-03-15 12:39:13.920733: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2023-03-15 12:39:13.949389: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-03-15 12:39:14.506206: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpvr47juxp\n",
      "2023-03-15 12:39:14.723361: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 919969 microseconds.\n",
      "2023-03-15 12:39:15.164318: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('clothing-model.tflite' , 'wb') as f_out :\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "251aa142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.1G\r\n",
      "-rw-rw-r-- 1 jovyan jovyan 5.4K Mar  7 16:45 1.jpg\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  11K Mar  7 16:44 2.jpg\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  13K Mar  7 16:44 3.jpg\r\n",
      "drwxrwsr-x 6 jovyan jovyan 4.0K Mar  7 15:43 clothing-dataset-small\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  83M Dec  7  2021 clothing-model.h5\r\n",
      "-rw-r--r-- 1 jovyan jovyan  81M Mar 15 12:39 clothing-model.tflite\r\n",
      "-rw-rw-r-- 1 jovyan jovyan 8.4K Mar 15 12:38 new_version_fashion_clothes.ipynb\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  525 Mar  7 14:39 README.md\r\n",
      "-rw-rw-r-- 1 jovyan jovyan 6.5K Mar  7 14:39 single-gpu-tensorflow.ipynb\r\n",
      "-rw-rw-r-- 1 jovyan jovyan 311K Mar 10 18:46 Untitled.ipynb\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  81M Mar  8 16:11 xception_v1_07_0.830.h5\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  83M Mar 10 17:05 xception_v4_01_0.806.h5\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  83M Mar 10 16:37 xception_v4_01_0.868.h5\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  83M Mar 10 17:06 xception_v4_02_0.818.h5\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  83M Mar 10 17:07 xception_v4_03_0.845.h5\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  83M Mar 10 16:38 xception_v4_04_0.886.h5\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  83M Mar 10 17:09 xception_v4_05_0.862.h5\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  83M Mar 10 17:10 xception_v4_06_0.865.h5\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  83M Mar 10 16:41 xception_v4_11_0.889.h5\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  83M Mar 10 17:16 xception_v4_12_0.874.h5\r\n",
      "-rw-rw-r-- 1 jovyan jovyan  83M Mar 10 16:52 xception_v4_34_0.900.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04461778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ddaa347",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tflite.Interpreter(model_path = 'clothing-model.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6c1f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index = interpreter.get_input_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "baac4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38fdf17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'clothing-dataset-small/test/pants/046d0a65-f5a6-47f6-afaf-e692bfcfcb00.jpg'\n",
    "img = load_img(path, target_size=(299, 299))\n",
    "x = np.array(img)\n",
    "X = np.array([x])\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef54567b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -2.781928,\n",
       " 'hat': -3.7481372,\n",
       " 'longsleeve': -3.3168318,\n",
       " 'outwear': -1.8005501,\n",
       " 'pants': 8.820292,\n",
       " 'shirt': -5.2966676,\n",
       " 'shoes': -3.3037236,\n",
       " 'shorts': 6.1636662,\n",
       " 'skirt': -0.33921242,\n",
       " 't-shirt': -3.4587955}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9f7fefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pants'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = max(res , key = res.get)\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba274afd",
   "metadata": {},
   "source": [
    "## Removing tensorflow dependencie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "136de2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8713e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'clothing-dataset-small/test/pants/046d0a65-f5a6-47f6-afaf-e692bfcfcb00.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50a61a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100/3913260517.py:2: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  img = img.resize((299 , 299) , Image.NEAREST)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with Image.open(path) as img :\n",
    "    img = img.resize((299 , 299) , Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46d75811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x /= 127.5\n",
    "    x -= 1.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51788f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img , dtype = 'float32')\n",
    "X = np.array([x])\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7bcf313",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_index , X)\n",
    "interpreter.invoke()\n",
    "pred = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d108544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -2.781928,\n",
       " 'hat': -3.7481372,\n",
       " 'longsleeve': -3.3168318,\n",
       " 'outwear': -1.8005501,\n",
       " 'pants': 8.820292,\n",
       " 'shirt': -5.2966676,\n",
       " 'shoes': -3.3037236,\n",
       " 'shorts': 6.1636662,\n",
       " 'skirt': -0.33921242,\n",
       " 't-shirt': -3.4587955}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing_list = ['dress', 'hat', 'longsleeve', 'outwear', 'pants', 'shirt', 'shoes', 'shorts', 'skirt', 't-shirt']\n",
    "res = dict(zip(clothing_list , pred[0]))\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbbacc8",
   "metadata": {},
   "source": [
    "## Simple way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78b953ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-image-helper\n",
      "  Downloading keras_image_helper-0.0.1-py3-none-any.whl (4.6 kB)\n",
      "Requirement already satisfied: pillow in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from keras-image-helper) (9.2.0)\n",
      "Requirement already satisfied: numpy in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from keras-image-helper) (1.21.6)\n",
      "Installing collected packages: keras-image-helper\n",
      "Successfully installed keras-image-helper-0.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install keras-image-helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "791bf44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_image_helper import create_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b2936d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = create_preprocessor('xception' , target_size = (299 , 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b1b8bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://bit.ly/mlbookcamp-pants'\n",
    "X = preprocessor.from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d3b4ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.11372548, -0.15294117, -0.19999999],\n",
       "         [-0.11372548, -0.15294117, -0.19999999],\n",
       "         [-0.10588235, -0.14509803, -0.19215685],\n",
       "         ...,\n",
       "         [-0.01960784, -0.01960784, -0.08235294],\n",
       "         [-0.04313725, -0.04313725, -0.10588235],\n",
       "         [-0.11372548, -0.11372548, -0.17647058]],\n",
       "\n",
       "        [[-0.09019607, -0.12941176, -0.17647058],\n",
       "         [-0.09019607, -0.12941176, -0.17647058],\n",
       "         [-0.08235294, -0.12156862, -0.16862744],\n",
       "         ...,\n",
       "         [-0.01960784, -0.01960784, -0.08235294],\n",
       "         [-0.04313725, -0.04313725, -0.10588235],\n",
       "         [-0.10588235, -0.10588235, -0.16862744]],\n",
       "\n",
       "        [[-0.09803921, -0.1372549 , -0.18431371],\n",
       "         [-0.09803921, -0.1372549 , -0.18431371],\n",
       "         [-0.09019607, -0.12941176, -0.17647058],\n",
       "         ...,\n",
       "         [-0.01960784, -0.01960784, -0.08235294],\n",
       "         [-0.03529412, -0.03529412, -0.09803921],\n",
       "         [-0.09019607, -0.09019607, -0.15294117]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.67058825, -0.7019608 , -0.7254902 ],\n",
       "         [-0.6862745 , -0.7176471 , -0.7411765 ],\n",
       "         [-0.70980394, -0.7411765 , -0.7647059 ],\n",
       "         ...,\n",
       "         [-0.62352943, -0.84313726, -0.9529412 ],\n",
       "         [-0.6313726 , -0.8509804 , -0.9607843 ],\n",
       "         [-0.6392157 , -0.85882354, -0.96862745]],\n",
       "\n",
       "        [[-0.52156866, -0.5529412 , -0.5764706 ],\n",
       "         [-0.52156866, -0.5529412 , -0.5764706 ],\n",
       "         [-0.5137255 , -0.54509807, -0.5686275 ],\n",
       "         ...,\n",
       "         [-0.5921569 , -0.8117647 , -0.92156863],\n",
       "         [-0.6       , -0.81960785, -0.92941177],\n",
       "         [-0.60784316, -0.827451  , -0.9372549 ]],\n",
       "\n",
       "        [[-0.62352943, -0.654902  , -0.6784314 ],\n",
       "         [-0.6156863 , -0.64705884, -0.67058825],\n",
       "         [-0.60784316, -0.6392157 , -0.6627451 ],\n",
       "         ...,\n",
       "         [-0.5686275 , -0.79607844, -0.90588236],\n",
       "         [-0.5764706 , -0.8039216 , -0.9137255 ],\n",
       "         [-0.58431375, -0.8117647 , -0.92156863]]]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "afbb3356",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_index , X)\n",
    "interpreter.invoke()\n",
    "pred = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d27374f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.8682916,\n",
       " 'hat': -4.7612457,\n",
       " 'longsleeve': -2.316979,\n",
       " 'outwear': -1.0625672,\n",
       " 'pants': 9.8871565,\n",
       " 'shirt': -2.8124275,\n",
       " 'shoes': -3.666287,\n",
       " 'shorts': 3.2003636,\n",
       " 'skirt': -2.6023414,\n",
       " 't-shirt': -4.8350444}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing_list = ['dress', 'hat', 'longsleeve', 'outwear', 'pants', 'shirt', 'shoes', 'shorts', 'skirt', 't-shirt']\n",
    "res = dict(zip(clothing_list , pred[0]))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a1db19ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://google-coral.github.io/py-repo/\n",
      "Collecting tflite_runtime\n",
      "  Downloading tflite_runtime-2.11.0-cp39-cp39-manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from tflite_runtime) (1.21.6)\n",
      "Installing collected packages: tflite_runtime\n",
      "Successfully installed tflite_runtime-2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --extra-index-url https://google-coral.github.io/py-repo/ tflite_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "344cf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow.lite as tflite\n",
    "import tflite_runtime.interpreter as tflite\n",
    "from keras_image_helper import create_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c4f8383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_path = 'clothing-model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c2a6b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = create_preprocessor('xception', target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b9b8d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://bit.ly/mlbookcamp-pants'\n",
    "X = preprocessor.from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b1bbdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9b53fef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.8682916,\n",
       " 'hat': -4.7612457,\n",
       " 'longsleeve': -2.316979,\n",
       " 'outwear': -1.0625672,\n",
       " 'pants': 9.8871565,\n",
       " 'shirt': -2.8124275,\n",
       " 'shoes': -3.666287,\n",
       " 'shorts': 3.2003636,\n",
       " 'skirt': -2.6023414,\n",
       " 't-shirt': -4.8350444}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]\n",
    "\n",
    "dict(zip(classes, preds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a4966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
